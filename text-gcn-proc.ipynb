{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-07T10:06:58.261478Z","iopub.execute_input":"2023-05-07T10:06:58.261892Z","iopub.status.idle":"2023-05-07T10:06:58.306253Z","shell.execute_reply.started":"2023-05-07T10:06:58.261857Z","shell.execute_reply":"2023-05-07T10:06:58.305114Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working/__notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:06:58.683030Z","iopub.execute_input":"2023-05-07T10:06:58.683498Z","iopub.status.idle":"2023-05-07T10:07:00.196416Z","shell.execute_reply.started":"2023-05-07T10:06:58.683461Z","shell.execute_reply":"2023-05-07T10:07:00.195217Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/abhishek-mishra14/text-gcn-covid.git","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:07:00.198703Z","iopub.execute_input":"2023-05-07T10:07:00.199220Z","iopub.status.idle":"2023-05-07T10:07:56.600437Z","shell.execute_reply.started":"2023-05-07T10:07:00.199183Z","shell.execute_reply":"2023-05-07T10:07:56.599283Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'text-gcn-covid'...\nremote: Enumerating objects: 26919, done.\u001b[K\nremote: Counting objects: 100% (102/102), done.\u001b[K\nremote: Compressing objects: 100% (53/53), done.\u001b[K\nremote: Total 26919 (delta 46), reused 102 (delta 46), pack-reused 26817\u001b[K\nReceiving objects: 100% (26919/26919), 984.85 MiB | 21.65 MiB/s, done.\nResolving deltas: 100% (257/257), done.\nUpdating files: 100% (184/184), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"os.chdir(\"/kaggle/working/text-gcn-covid\")","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:07:56.602433Z","iopub.execute_input":"2023-05-07T10:07:56.602820Z","iopub.status.idle":"2023-05-07T10:07:56.607803Z","shell.execute_reply.started":"2023-05-07T10:07:56.602785Z","shell.execute_reply":"2023-05-07T10:07:56.606769Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:40:15.025185Z","iopub.execute_input":"2023-05-07T09:40:15.025496Z","iopub.status.idle":"2023-05-07T09:40:15.994342Z","shell.execute_reply.started":"2023-05-07T09:40:15.025468Z","shell.execute_reply":"2023-05-07T09:40:15.993013Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/BertGCN\n","output_type":"stream"}]},{"cell_type":"code","source":"!git pull","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:40:15.998205Z","iopub.execute_input":"2023-05-07T09:40:16.000857Z","iopub.status.idle":"2023-05-07T09:40:17.395503Z","shell.execute_reply.started":"2023-05-07T09:40:16.000815Z","shell.execute_reply":"2023-05-07T09:40:17.394236Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Already up to date.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python remove_words.py covid-semi","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:07:56.610443Z","iopub.execute_input":"2023-05-07T10:07:56.610829Z","iopub.status.idle":"2023-05-07T10:08:02.072129Z","shell.execute_reply.started":"2023-05-07T10:07:56.610754Z","shell.execute_reply":"2023-05-07T10:08:02.070909Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n{'each', 'himself', 'into', 'how', \"you'll\", 'below', 'before', 'no', 'after', 'then', 'm', 'that', 'couldn', 'myself', 'we', 'this', 'against', 'o', 'but', \"isn't\", 'of', 'when', 'above', 'up', 'too', \"aren't\", 'am', 'your', 'until', 'doing', \"you'd\", 'just', 'while', 'from', 'they', 'its', 'once', 'very', 'their', 'did', 'and', 'don', \"she's\", 'it', \"needn't\", 'on', 'here', \"should've\", 'does', 'the', 'or', 'ourselves', 'do', \"mightn't\", 'wasn', 'mustn', \"shan't\", 'his', 'll', 'themselves', 'be', 'which', \"wouldn't\", \"you're\", 'will', 'isn', 'our', 'didn', 'were', \"couldn't\", 'my', 'hers', 'him', \"that'll\", 'between', \"didn't\", 'is', \"don't\", 'shan', 's', \"haven't\", 'both', \"weren't\", 'yours', 'again', 'she', 'so', 're', 'at', 'these', 'because', 'than', 'hadn', 'ma', 'some', \"hasn't\", 'during', 'out', 'has', 'off', 'with', 'being', 'been', 'are', 'itself', 'mightn', 'those', \"wasn't\", 'can', 'ain', 'theirs', 'why', 'same', 'if', \"doesn't\", 'ours', 'not', 'under', 'nor', 'her', 'weren', 'hasn', 'had', 'you', 'should', 't', 'to', 'who', 'yourself', 'through', 'needn', \"you've\", \"it's\", 'over', 'won', 'wouldn', 'down', 'more', 'most', 'there', 'he', 'i', 'as', 'other', 'only', 'd', 'a', 'all', 'them', 'for', 'doesn', 'in', 'such', 'yourselves', 'have', 'having', 'what', 'aren', 'an', 've', 'y', 'shouldn', \"hadn't\", \"shouldn't\", 'where', 'whom', 'further', 'any', 'now', 'me', 'herself', \"mustn't\", 'few', 'own', 'about', 'haven', 'by', 'was', \"won't\"}\nmin_len : 9\nmax_len : 537\naverage_len : 123.78024216363019\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# BUILD GRAPH","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pickle as pkl\nimport networkx as nx\nimport scipy.sparse as sp\nfrom utils import loadWord2Vec, clean_str\nfrom math import log\nfrom sklearn import svm\nfrom nltk.corpus import wordnet as wn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport sys\nfrom scipy.spatial.distance import cosine","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:13:07.161107Z","iopub.execute_input":"2023-05-07T10:13:07.161711Z","iopub.status.idle":"2023-05-07T10:13:07.397386Z","shell.execute_reply.started":"2023-05-07T10:13:07.161668Z","shell.execute_reply":"2023-05-07T10:13:07.396385Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"dataset = 'covid-semi'","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:13:10.389199Z","iopub.execute_input":"2023-05-07T10:13:10.390212Z","iopub.status.idle":"2023-05-07T10:13:10.396084Z","shell.execute_reply.started":"2023-05-07T10:13:10.390167Z","shell.execute_reply":"2023-05-07T10:13:10.395079Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"word_embeddings_dim = 300\nword_vector_map = {}\n\n# shulffing\ndoc_name_list = []\ndoc_train_list = []\ndoc_test_list = []\ndoc_eval_list = []\n\nf = open('data/' + dataset + '.txt', 'r')\nlines = f.readlines()\nfor line in lines:\n    doc_name_list.append(line.strip())\n    temp = line.split(\"\\t\")\n    if temp[1].find('test') != -1:\n        doc_test_list.append(line.strip())\n    elif temp[1].find('train') != -1:\n        doc_train_list.append(line.strip())\n    elif temp[1].find(\"eval\") != -1:\n        doc_train_list.append(line.strip())\n        doc_eval_list.append(line.strip())\n        \nf.close()\nprint(\"Doc Train List: \",len(doc_train_list))\nprint(\"Doc Test List: \",len(doc_test_list))\nprint(\"Doc Eval List: \", len(doc_eval_list))\n\ndoc_content_list = []\nf = open('data/corpus/' + dataset + '.clean.txt', 'r')\nlines = f.readlines()\nfor line in lines:\n    doc_content_list.append(line.strip())\nf.close()\n\ntrain_ids = []\nfor train_name in doc_train_list:\n    train_id = doc_name_list.index(train_name)\n    train_ids.append(train_id)\nprint(train_ids)\n# random.shuffle(train_ids)\n\n# partial labeled data\n#train_ids = train_ids[:int(0.2 * len(train_ids))]\n\ntrain_ids_str = '\\n'.join(str(index) for index in train_ids)\nf = open('data/' + dataset + '.train.index', 'w')\nf.write(train_ids_str)\nf.close()\n\ntest_ids = []\nfor test_name in doc_test_list:\n    test_id = doc_name_list.index(test_name)\n    test_ids.append(test_id)\n# print(test_ids)\n# random.shuffle(test_ids)\n\neval_ids = []\nfor eval_name in doc_eval_list:\n    eval_id = doc_name_list.index(eval_name)\n    eval_ids.append(eval_id)\nprint(eval_ids)\n# random.shuffle(eval_ids)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:13:11.944340Z","iopub.execute_input":"2023-05-07T10:13:11.944700Z","iopub.status.idle":"2023-05-07T10:13:12.934307Z","shell.execute_reply.started":"2023-05-07T10:13:11.944670Z","shell.execute_reply":"2023-05-07T10:13:12.933299Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Doc Train List:  188\nDoc Test List:  8645\nDoc Eval List:  0\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187]\n[]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ids_str = '\\n'.join(str(index) for index in test_ids)\nf = open('data/' + dataset + '.test.index', 'w')\nf.write(test_ids_str)\nf.close()\n\nids = train_ids + test_ids\nprint(ids)\nprint(len(ids))\n\nshuffle_doc_name_list = []\nshuffle_doc_words_list = []\nfor id in ids:\n    shuffle_doc_name_list.append(doc_name_list[int(id)])\n    shuffle_doc_words_list.append(doc_content_list[int(id)])\nshuffle_doc_name_str = '\\n'.join(shuffle_doc_name_list)\nshuffle_doc_words_str = '\\n'.join(shuffle_doc_words_list)\n\nf = open('data/' + dataset + '_shuffle.txt', 'w')\nf.write(shuffle_doc_name_str)\nf.close()\n\nf = open('data/corpus/' + dataset + '_shuffle.txt', 'w')\nf.write(shuffle_doc_words_str)\nf.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_freq = {}\nword_set = set()\nfor doc_words in shuffle_doc_words_list:\n    words = doc_words.split()\n    for word in words:\n        word_set.add(word)\n        if word in word_freq:\n            word_freq[word] += 1\n        else:\n            word_freq[word] = 1\n\nvocab = list(word_set)\nvocab_size = len(vocab)\n\nprint(\"Vocab size: \", vocab_size)\n\nword_doc_list = {}\n\nfor i in range(len(shuffle_doc_words_list)):\n    doc_words = shuffle_doc_words_list[i]\n    words = doc_words.split()\n    appeared = set()\n    for word in words:\n        if word in appeared:\n            continue\n        if word in word_doc_list:\n            doc_list = word_doc_list[word]\n            doc_list.append(i)\n            word_doc_list[word] = doc_list\n        else:\n            word_doc_list[word] = [i]\n        appeared.add(word)\n\nword_doc_freq = {}\nfor word, doc_list in word_doc_list.items():\n    word_doc_freq[word] = len(doc_list)\n\nword_id_map = {}\n\nfor i in range(vocab_size):\n    word_id_map[vocab[i]] = i\n\nvocab_str = '\\n'.join(vocab)\n\nf = open('data/corpus/' + dataset + '_vocab.txt', 'w')\nf.write(vocab_str)\nf.close()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:33:27.963814Z","iopub.execute_input":"2023-05-07T08:33:27.964746Z","iopub.status.idle":"2023-05-07T08:33:28.864504Z","shell.execute_reply.started":"2023-05-07T08:33:27.964701Z","shell.execute_reply":"2023-05-07T08:33:28.863601Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Vocab size:  13411\n","output_type":"stream"}]},{"cell_type":"code","source":"label_set = set()\nfor doc_meta in shuffle_doc_name_list:\n    temp = doc_meta.split('\\t')\n    if temp[1].find('train') != -1:\n        label_set.add(temp[2])\nlabel_list = list(label_set)\n\n# label_list\n\nlabel_list_str = '\\n'.join(label_list)\nf = open('data/corpus/' + dataset + '_labels.txt', 'w')\nf.write(label_list_str)\nf.close()\n\n# x: feature vectors of training docs, no initial features\n# slect 90% training set\ntrain_size = len(train_ids)\nval_size = len(eval_ids)\nreal_train_size = train_size - val_size  # - int(0.5 * train_size)\nprint(real_train_size)\n# different training rates\n\nreal_train_doc_names = shuffle_doc_name_list[:real_train_size]\n# print(real_train_doc_names)\nreal_train_doc_names_str = '\\n'.join(real_train_doc_names)\n\n# print(real_train_doc_names_str)\n\nf = open('data/' + dataset + '.real_train.name', 'w')\nf.write(real_train_doc_names_str)\nf.close()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:33:28.866236Z","iopub.execute_input":"2023-05-07T08:33:28.866713Z","iopub.status.idle":"2023-05-07T08:33:28.881084Z","shell.execute_reply.started":"2023-05-07T08:33:28.866678Z","shell.execute_reply":"2023-05-07T08:33:28.880050Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"150\n","output_type":"stream"}]},{"cell_type":"code","source":"row_x = []\ncol_x = []\ndata_x = []\nfor i in range(real_train_size):\n    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n    doc_words = shuffle_doc_words_list[i]\n    words = doc_words.split()\n    doc_len = len(words)\n    for word in words:\n        if word in word_vector_map:\n            word_vector = word_vector_map[word]\n            print(doc_vec)\n            print(np.array(word_vector))\n            doc_vec = doc_vec + np.array(word_vector)\n\n    for j in range(word_embeddings_dim):\n        row_x.append(i)\n        col_x.append(j)\n        # np.random.uniform(-0.25, 0.25)\n        data_x.append(doc_vec[j] / doc_len)  # doc_vec[j]/ doc_len\n\n# x = sp.csr_matrix((real_train_size, word_embeddings_dim), dtype=np.float32)\nx = sp.csr_matrix((data_x, (row_x, col_x)), shape=(\n    real_train_size, word_embeddings_dim))\nx","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:33:28.882217Z","iopub.execute_input":"2023-05-07T08:33:28.882824Z","iopub.status.idle":"2023-05-07T08:33:28.939545Z","shell.execute_reply.started":"2023-05-07T08:33:28.882793Z","shell.execute_reply":"2023-05-07T08:33:28.938715Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<150x300 sparse matrix of type '<class 'numpy.float64'>'\n\twith 45000 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"y = []\nfor i in range(real_train_size):\n    doc_meta = shuffle_doc_name_list[i]\n    temp = doc_meta.split('\\t')\n    label = temp[2]\n    one_hot = [0 for l in range(len(label_list))]\n    label_index = label_list.index(label)\n    one_hot[label_index] = 1\n    y.append(one_hot)\ny = np.array(y)\n# print(y)\n\n# tx: feature vectors of test docs, no initial features\ntest_size = len(test_ids)\n\nrow_tx = []\ncol_tx = []\ndata_tx = []\n\nfor i in range(test_size):\n    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n    doc_words = shuffle_doc_words_list[i + train_size]\n    words = doc_words.split()\n    doc_len = len(words)\n    for word in words:\n        if word in word_vector_map:\n            word_vector = word_vector_map[word]\n            doc_vec = doc_vec + np.array(word_vector)\n\n    for j in range(word_embeddings_dim):\n        row_tx.append(i)\n        col_tx.append(j)\n        # np.random.uniform(-0.25, 0.25)\n        data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len\n\n# tx = sp.csr_matrix((test_size, word_embeddings_dim), dtype=np.float32)\ntx = sp.csr_matrix((data_tx, (row_tx, col_tx)),\n                   shape=(test_size, word_embeddings_dim))\ntx\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:33:28.941571Z","iopub.execute_input":"2023-05-07T08:33:28.941986Z","iopub.status.idle":"2023-05-07T08:33:31.659458Z","shell.execute_reply.started":"2023-05-07T08:33:28.941955Z","shell.execute_reply":"2023-05-07T08:33:31.658519Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<8645x300 sparse matrix of type '<class 'numpy.float64'>'\n\twith 2593500 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"ty = []\nfor i in range(test_size):\n    doc_meta = shuffle_doc_name_list[i + train_size]\n    temp = doc_meta.split('\\t')\n    label = temp[2]\n    one_hot = [0 for l in range(len(label_list))]\n    try:\n        label_index = label_list.index(label)\n    except Exception as e:\n        label_index = -1\n    if label_index >= 0:\n        one_hot[label_index] = 1\n    ty.append(one_hot)\nty = np.array(ty)\nprint(ty)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:33:31.660849Z","iopub.execute_input":"2023-05-07T08:33:31.661210Z","iopub.status.idle":"2023-05-07T08:33:31.783871Z","shell.execute_reply.started":"2023-05-07T08:33:31.661180Z","shell.execute_reply":"2023-05-07T08:33:31.782743Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[[0 0]\n [0 0]\n [0 0]\n ...\n [0 0]\n [0 0]\n [0 0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nword_vectors = np.random.uniform(-0.01, 0.01,\n                                 (vocab_size, word_embeddings_dim))\n\nfor i in range(len(vocab)):\n    word = vocab[i]\n    if word in word_vector_map:\n        vector = word_vector_map[word]\n        word_vectors[i] = vector\n\n\nrow_allx = []\ncol_allx = []\ndata_allx = []\n\nfor i in range(train_size):\n    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n    doc_words = shuffle_doc_words_list[i]\n    words = doc_words.split()\n    doc_len = len(words)\n    for word in words:\n        if word in word_vector_map:\n            word_vector = word_vector_map[word]\n            doc_vec = doc_vec + np.array(word_vector)\n\n    for j in range(word_embeddings_dim):\n        row_allx.append(int(i))\n        col_allx.append(j)\n        # np.random.uniform(-0.25, 0.25)\n        data_allx.append(doc_vec[j] / doc_len)  # doc_vec[j]/doc_len\n# print(row_allx)\nfor i in range(vocab_size):\n    for j in range(word_embeddings_dim):\n        row_allx.append(int(i + train_size))\n        col_allx.append(j)\n        data_allx.append(word_vectors.item((i, j)))\n        \nrow_allx = np.array(row_allx)\ncol_allx = np.array(col_allx)\ndata_allx = np.array(data_allx)\n\n# print(data_allx)\n\nallx = sp.csr_matrix(\n    (data_allx, (row_allx, col_allx)), shape=(train_size + vocab_size, word_embeddings_dim))\n\nally = []\nfor i in range(train_size):\n    doc_meta = shuffle_doc_name_list[i]\n    temp = doc_meta.split('\\t')\n    label = temp[2]\n    one_hot = [0 for l in range(len(label_list))]\n    label_index = label_list.index(label)\n    one_hot[label_index] = 1\n    ally.append(one_hot)\n\nfor i in range(vocab_size):\n    one_hot = [0 for l in range(len(label_list))]\n    ally.append(one_hot)\n\n# print(ally)\nally = np.array(ally)\nprint(x.shape, y.shape, tx.shape, ty.shape, allx.shape, ally.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:33:31.786323Z","iopub.execute_input":"2023-05-07T08:33:31.786716Z","iopub.status.idle":"2023-05-07T08:33:35.514338Z","shell.execute_reply.started":"2023-05-07T08:33:31.786685Z","shell.execute_reply":"2023-05-07T08:33:35.513387Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(150, 300) (150, 2) (8645, 300) (8645, 2) (13599, 300) (13599, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"window_size = 20\nwindows = []\n\nfor doc_words in shuffle_doc_words_list:\n    words = doc_words.split()\n    length = len(words)\n    if length <= window_size:\n        windows.append(words)\n    else:\n        # print(length, length - window_size + 1)\n        for j in range(length - window_size + 1):\n            window = words[j: j + window_size]\n            windows.append(window)\nprint(\"Windows: \", len(windows))\nword_window_freq = {}\nfor window in windows:\n    appeared = set()\n    for i in range(len(window)):\n        if window[i] in appeared:\n            continue\n        if window[i] in word_window_freq:\n            word_window_freq[window[i]] += 1\n        else:\n            word_window_freq[window[i]] = 1\n        appeared.add(window[i])\nprint(len(word_window_freq))\n\nword_pair_count = {}\n\nfor window in windows:\n    for i in range(1, len(window)):\n        for j in range(0, i):\n            word_i = window[i]\n            word_i_id = word_id_map[word_i]\n            word_j = window[j]\n            word_j_id = word_id_map[word_j]\n            if word_i_id == word_j_id:\n                continue\n            word_pair_str = str(word_i_id) + ',' + str(word_j_id)\n            if word_pair_str in word_pair_count:\n                word_pair_count[word_pair_str] += 1\n            else:\n                word_pair_count[word_pair_str] = 1\n            # two orders\n            word_pair_str = str(word_j_id) + ',' + str(word_i_id)\n            if word_pair_str in word_pair_count:\n                word_pair_count[word_pair_str] += 1\n            else:\n                word_pair_count[word_pair_str] = 1\n# cat, dog => dog, cat\nprint(len(word_pair_count))\n                \nrow = []\ncol = []\nweight = []\n\n# pmi as weights\n\nnum_window = len(windows)\n\nfor key in word_pair_count:\n    temp = key.split(',')\n    i = int(temp[0])\n    j = int(temp[1])\n    count = word_pair_count[key]\n    word_freq_i = word_window_freq[vocab[i]]\n    word_freq_j = word_window_freq[vocab[j]]\n    pmi = log((1.0 * count / num_window) /\n              (1.0 * word_freq_i * word_freq_j/(num_window * num_window)))\n    if pmi <= 0:\n        continue\n    row.append(train_size + i)\n    col.append(train_size + j)\n    weight.append(pmi)\n    \ndoc_word_freq = {}\n\nfor doc_id in range(len(shuffle_doc_words_list)):\n    doc_words = shuffle_doc_words_list[doc_id]\n    words = doc_words.split()\n    for word in words:\n        word_id = word_id_map[word]\n        doc_word_str = str(doc_id) + ',' + str(word_id)\n        if doc_word_str in doc_word_freq:\n            doc_word_freq[doc_word_str] += 1\n        else:\n            doc_word_freq[doc_word_str] = 1","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:33:35.516062Z","iopub.execute_input":"2023-05-07T08:33:35.516458Z","iopub.status.idle":"2023-05-07T08:39:37.393764Z","shell.execute_reply.started":"2023-05-07T08:33:35.516426Z","shell.execute_reply":"2023-05-07T08:39:37.392816Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Windows:  925466\n13411\n8391198\n","output_type":"stream"}]},{"cell_type":"code","source":"len(doc_word_freq)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:39:44.125758Z","iopub.execute_input":"2023-05-07T08:39:44.126126Z","iopub.status.idle":"2023-05-07T08:39:44.131824Z","shell.execute_reply.started":"2023-05-07T08:39:44.126095Z","shell.execute_reply":"2023-05-07T08:39:44.130792Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"650723"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(len(shuffle_doc_words_list)):\n    doc_words = shuffle_doc_words_list[i]\n    words = doc_words.split()\n    doc_word_set = set()\n    for word in words:\n        if word in doc_word_set:\n            continue\n        j = word_id_map[word]\n        key = str(i) + ',' + str(j)\n        freq = doc_word_freq[key]\n        if i < train_size:\n            row.append(i)\n        else:\n            row.append(i + vocab_size)\n        col.append(train_size + j)\n        idf = log(1.0 * len(shuffle_doc_words_list) /\n                  word_doc_freq[vocab[j]])\n        weight.append(freq * idf)\n        doc_word_set.add(word)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:39:45.023054Z","iopub.execute_input":"2023-05-07T08:39:45.023393Z","iopub.status.idle":"2023-05-07T08:39:46.632371Z","shell.execute_reply.started":"2023-05-07T08:39:45.023366Z","shell.execute_reply":"2023-05-07T08:39:46.631431Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\nnode_size = train_size + vocab_size + test_size\nadj = sp.csr_matrix(\n    (weight, (row, col)), shape=(node_size, node_size))","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:39:47.948140Z","iopub.execute_input":"2023-05-07T08:39:47.948715Z","iopub.status.idle":"2023-05-07T08:39:50.261031Z","shell.execute_reply.started":"2023-05-07T08:39:47.948682Z","shell.execute_reply":"2023-05-07T08:39:50.260105Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"f = open(\"data/ind.{}.x\".format(dataset), 'wb')\npkl.dump(x, f)\nf.close()\n\nf = open(\"data/ind.{}.y\".format(dataset), 'wb')\npkl.dump(y, f)\nf.close()\n\nf = open(\"data/ind.{}.tx\".format(dataset), 'wb')\npkl.dump(tx, f)\nf.close()\n\nf = open(\"data/ind.{}.ty\".format(dataset), 'wb')\npkl.dump(ty, f)\nf.close()\n\nf = open(\"data/ind.{}.allx\".format(dataset), 'wb')\npkl.dump(allx, f)\nf.close()\n\nf = open(\"data/ind.{}.ally\".format(dataset), 'wb')\npkl.dump(ally, f)\nf.close()\n\nf = open(\"data/ind.{}.adj\".format(dataset), 'wb')\npkl.dump(adj, f)\nf.close()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:39:50.262773Z","iopub.execute_input":"2023-05-07T08:39:50.263098Z","iopub.status.idle":"2023-05-07T08:39:50.497342Z","shell.execute_reply.started":"2023-05-07T08:39:50.263068Z","shell.execute_reply":"2023-05-07T08:39:50.496380Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# FINETUNE BERT","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:38:23.876498Z","iopub.execute_input":"2023-05-02T21:38:23.876932Z","iopub.status.idle":"2023-05-02T21:38:32.775123Z","shell.execute_reply.started":"2023-05-02T21:38:23.876899Z","shell.execute_reply":"2023-05-02T21:38:32.77402Z"}}},{"cell_type":"code","source":"import torch as th\nfrom transformers import AutoModel, AutoTokenizer\nimport torch.nn.functional as F\nfrom utils import *\nimport dgl\nimport torch.utils.data as Data\nfrom ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer, Engine\nfrom ignite.metrics import Accuracy, Loss\nimport numpy as np\nimport os\nfrom datetime import datetime\nfrom sklearn.metrics import accuracy_score\nimport argparse, shutil, logging\nfrom torch.optim import lr_scheduler\nfrom model import BertClassifier","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:40:34.963627Z","iopub.execute_input":"2023-05-07T09:40:34.963955Z","iopub.status.idle":"2023-05-07T09:40:40.040459Z","shell.execute_reply.started":"2023-05-07T09:40:34.963928Z","shell.execute_reply":"2023-05-07T09:40:40.039546Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nDGL backend not selected or invalid.  Assuming PyTorch for now.\n","output_type":"stream"},{"name":"stdout","text":"Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.argv = sys.argv[1:]","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:40:51.239228Z","iopub.execute_input":"2023-05-07T09:40:51.239575Z","iopub.status.idle":"2023-05-07T09:40:51.245306Z","shell.execute_reply.started":"2023-05-07T09:40:51.239547Z","shell.execute_reply":"2023-05-07T09:40:51.244413Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument('--max_length', type=int, default=128, help='the input length for bert')\nparser.add_argument('--batch_size', type=int, default=64)\nparser.add_argument('--nb_epochs', type=int, default=15)\nparser.add_argument('--bert_lr', type=float, default=1e-4)\nparser.add_argument('--dataset', default='covid-semi', choices=['20ng', 'R8', 'R52', 'ohsumed', 'mr', 'covid-semi'])\nparser.add_argument('--bert_init', type=str, default='roberta-base',\n                    choices=['roberta-base', 'roberta-large', 'bert-base-uncased', 'bert-large-uncased'])\nparser.add_argument('--checkpoint_dir', default=None, help='checkpoint directory, [bert_init]_[dataset] if not specified')\n\nargs = parser.parse_args()\n\nmax_length = args.max_length\nbatch_size = args.batch_size\nnb_epochs = args.nb_epochs\nbert_lr = args.bert_lr\ndataset = args.dataset\nbert_init = args.bert_init\ncheckpoint_dir = args.checkpoint_dir\nif checkpoint_dir is None:\n    ckpt_dir = './checkpoint/{}_{}'.format(bert_init, dataset)\nelse:\n    ckpt_dir = checkpoint_dir\n\nos.makedirs(ckpt_dir, exist_ok=True)\n# shutil.copy(os.path.basename(__file__), ckpt_dir)\n\nsh = logging.StreamHandler(sys.stdout)\nsh.setFormatter(logging.Formatter('%(message)s'))\nsh.setLevel(logging.INFO)\nfh = logging.FileHandler(filename=os.path.join(ckpt_dir, 'training.log'), mode='w')\nfh.setFormatter(logging.Formatter('%(message)s'))\nfh.setLevel(logging.INFO)\nlogger = logging.getLogger('training logger')\nlogger.addHandler(sh)\nlogger.addHandler(fh)\nlogger.setLevel(logging.INFO)\n\ncpu = th.device('cpu')\ngpu = th.device('cuda:0')\n\nlogger.info('arguments:')\nlogger.info(str(args))\nlogger.info('checkpoints will be saved in {}'.format(ckpt_dir))","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:40:53.720587Z","iopub.execute_input":"2023-05-07T09:40:53.720932Z","iopub.status.idle":"2023-05-07T09:40:53.736360Z","shell.execute_reply.started":"2023-05-07T09:40:53.720904Z","shell.execute_reply":"2023-05-07T09:40:53.735427Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"arguments:\nNamespace(max_length=128, batch_size=64, nb_epochs=15, bert_lr=0.0001, dataset='covid-semi', bert_init='roberta-base', checkpoint_dir=None)\ncheckpoints will be saved in ./checkpoint/roberta-base_covid-semi\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data Preprocess\nadj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(dataset)\n'''\ny_train, y_val, y_test: n*c matrices \ntrain_mask, val_mask, test_mask: n-d bool array\ntrain_size, test_size: unused\n'''","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:03.208191Z","iopub.execute_input":"2023-05-07T09:41:03.208531Z","iopub.status.idle":"2023-05-07T09:41:04.216920Z","shell.execute_reply.started":"2023-05-07T09:41:03.208498Z","shell.execute_reply":"2023-05-07T09:41:04.215955Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(150, 300) (150, 2) (8645, 300) (8645, 2) (13599, 300) (13599, 2)\n22244\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'\\ny_train, y_val, y_test: n*c matrices \\ntrain_mask, val_mask, test_mask: n-d bool array\\ntrain_size, test_size: unused\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# compute number of real train/val/test/word nodes and number of classes\nnb_node = adj.shape[0]\nnb_train, nb_val, nb_test = train_mask.sum(), val_mask.sum(), test_mask.sum()\nnb_word = nb_node - nb_train - nb_val - nb_test\nnb_class = y_train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:04.218817Z","iopub.execute_input":"2023-05-07T09:41:04.219698Z","iopub.status.idle":"2023-05-07T09:41:04.226732Z","shell.execute_reply.started":"2023-05-07T09:41:04.219638Z","shell.execute_reply":"2023-05-07T09:41:04.225386Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"nb_train, nb_val, nb_test, nb_word, nb_class","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:05.543757Z","iopub.execute_input":"2023-05-07T09:41:05.544407Z","iopub.status.idle":"2023-05-07T09:41:05.654498Z","shell.execute_reply.started":"2023-05-07T09:41:05.544373Z","shell.execute_reply":"2023-05-07T09:41:05.653584Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(150, 38, 8645, 13411, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# instantiate model according to class number\nmodel = BertClassifier(pretrained_model=bert_init, nb_class=nb_class)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:06.747023Z","iopub.execute_input":"2023-05-07T09:41:06.747408Z","iopub.status.idle":"2023-05-07T09:41:19.887765Z","shell.execute_reply.started":"2023-05-07T09:41:06.747377Z","shell.execute_reply":"2023-05-07T09:41:19.886796Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4381f2fb964e16a54729c8292944b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bedb5ae78f2d4639b1e756ce1ddb3e6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367b63a082d24201b20c9d705e09363e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7892eb8d0414c35bcd32276bef6dffc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"311b73e65e8744a4adf4d8de9f198a34"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"# transform one-hot label to class ID for pytorch computation\ny = th.LongTensor((y_train + y_val +y_test).argmax(axis=1))\nlabel = {}\nlabel['train'], label['val'], label['test'] = y[:nb_train], y[nb_train:nb_train+nb_val], y[-nb_test:]","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:19.889749Z","iopub.execute_input":"2023-05-07T09:41:19.890104Z","iopub.status.idle":"2023-05-07T09:41:19.904916Z","shell.execute_reply.started":"2023-05-07T09:41:19.890070Z","shell.execute_reply":"2023-05-07T09:41:19.903874Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# load documents and compute input encodings\ncorpus_file = './data/corpus/'+dataset+'_shuffle.txt'\nwith open(corpus_file, 'r') as f:\n    text = f.read()\n    text=text.replace('\\\\', '')\n    text = text.split('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:19.906190Z","iopub.execute_input":"2023-05-07T09:41:19.906616Z","iopub.status.idle":"2023-05-07T09:41:19.952168Z","shell.execute_reply.started":"2023-05-07T09:41:19.906583Z","shell.execute_reply":"2023-05-07T09:41:19.951199Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def encode_input(text, tokenizer):\n    input = tokenizer(text, max_length=max_length, truncation=True, padding=True, return_tensors='pt')\n    return input.input_ids, input.attention_mask\n\ninput_ids, attention_mask = {}, {}\n\ninput_ids_, attention_mask_ = encode_input(text, model.tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:19.954400Z","iopub.execute_input":"2023-05-07T09:41:19.954789Z","iopub.status.idle":"2023-05-07T09:41:23.315049Z","shell.execute_reply.started":"2023-05-07T09:41:19.954753Z","shell.execute_reply":"2023-05-07T09:41:23.313881Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# create train/test/val datasets and dataloaders\ninput_ids['train'], input_ids['val'], input_ids['test'] =  input_ids_[:nb_train], input_ids_[nb_train:nb_train+nb_val], input_ids_[-nb_test:]\nattention_mask['train'], attention_mask['val'], attention_mask['test'] =  attention_mask_[:nb_train], attention_mask_[nb_train:nb_train+nb_val], attention_mask_[-nb_test:]","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:23.316606Z","iopub.execute_input":"2023-05-07T09:41:23.317168Z","iopub.status.idle":"2023-05-07T09:41:23.323072Z","shell.execute_reply.started":"2023-05-07T09:41:23.317133Z","shell.execute_reply":"2023-05-07T09:41:23.322033Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"datasets = {}\nloader = {}\nfor split in ['train', 'val', 'test']:\n    datasets[split] =  Data.TensorDataset(input_ids[split], attention_mask[split], label[split])\n    loader[split] = Data.DataLoader(datasets[split], batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:23.327431Z","iopub.execute_input":"2023-05-07T09:41:23.327840Z","iopub.status.idle":"2023-05-07T09:41:23.494507Z","shell.execute_reply.started":"2023-05-07T09:41:23.327802Z","shell.execute_reply":"2023-05-07T09:41:23.493383Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Training\n\noptimizer = th.optim.Adam(model.parameters(), lr=bert_lr)\nscheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30], gamma=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:27.218191Z","iopub.execute_input":"2023-05-07T09:41:27.218541Z","iopub.status.idle":"2023-05-07T09:41:27.228817Z","shell.execute_reply.started":"2023-05-07T09:41:27.218513Z","shell.execute_reply":"2023-05-07T09:41:27.227656Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def train_step(engine, batch):\n    global model, optimizer\n    model.train()\n    model = model.to(gpu)\n    optimizer.zero_grad()\n    (input_ids, attention_mask, label) = [x.to(gpu) for x in batch]\n    optimizer.zero_grad()\n    y_pred = model(input_ids, attention_mask)\n    y_true = label.type(th.long)\n    loss = F.cross_entropy(y_pred, y_true)\n    loss.backward()\n    optimizer.step()\n    train_loss = loss.item()\n    with th.no_grad():\n        y_true = y_true.detach().cpu()\n        y_pred = y_pred.argmax(axis=1).detach().cpu()\n        train_acc = accuracy_score(y_true, y_pred)\n    return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:27.586983Z","iopub.execute_input":"2023-05-07T09:41:27.587335Z","iopub.status.idle":"2023-05-07T09:41:28.403696Z","shell.execute_reply.started":"2023-05-07T09:41:27.587306Z","shell.execute_reply":"2023-05-07T09:41:28.402491Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\ntrainer = Engine(train_step)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:28.406525Z","iopub.execute_input":"2023-05-07T09:41:28.407311Z","iopub.status.idle":"2023-05-07T09:41:28.416404Z","shell.execute_reply.started":"2023-05-07T09:41:28.407274Z","shell.execute_reply":"2023-05-07T09:41:28.415496Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def test_step(engine, batch):\n    global model\n    with th.no_grad():\n        model.eval()\n        model = model.to(gpu)\n        (input_ids, attention_mask, label) = [x.to(gpu) for x in batch]\n        optimizer.zero_grad()\n        y_pred = model(input_ids, attention_mask)\n        y_true = label\n        return y_pred, y_true\n\n\nevaluator = Engine(test_step)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:28.418776Z","iopub.execute_input":"2023-05-07T09:41:28.419030Z","iopub.status.idle":"2023-05-07T09:41:28.426160Z","shell.execute_reply.started":"2023-05-07T09:41:28.419007Z","shell.execute_reply":"2023-05-07T09:41:28.425283Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"metrics={\n    'acc': Accuracy(),\n    'nll': Loss(th.nn.CrossEntropyLoss())\n}\nfor n, f in metrics.items():\n    f.attach(evaluator, n)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:29.028877Z","iopub.execute_input":"2023-05-07T09:41:29.029229Z","iopub.status.idle":"2023-05-07T09:41:29.034595Z","shell.execute_reply.started":"2023-05-07T09:41:29.029199Z","shell.execute_reply":"2023-05-07T09:41:29.033733Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"@trainer.on(Events.EPOCH_COMPLETED)\ndef log_training_results(trainer):\n    evaluator.run(loader['train'])\n    metrics = evaluator.state.metrics\n    train_acc, train_nll = metrics[\"acc\"], metrics[\"nll\"]\n    evaluator.run(loader['val'])\n    metrics = evaluator.state.metrics\n    val_acc, val_nll = metrics[\"acc\"], metrics[\"nll\"]\n    evaluator.run(loader['test'])\n    metrics = evaluator.state.metrics\n    test_acc, test_nll = metrics[\"acc\"], metrics[\"nll\"]\n    logger.info(\n        \"\\rEpoch: {}  Train acc: {:.4f} loss: {:.4f}  Val acc: {:.4f} loss: {:.4f}  Test acc: {:.4f} loss: {:.4f}\"\n        .format(trainer.state.epoch, train_acc, train_nll, val_acc, val_nll, test_acc, test_nll)\n    )\n    if val_acc > log_training_results.best_val_acc:\n        logger.info(\"New checkpoint\")\n        th.save(\n            {\n                'bert_model': model.bert_model.state_dict(),\n                'classifier': model.classifier.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'epoch': trainer.state.epoch,\n            },\n            os.path.join(\n                ckpt_dir, 'checkpoint.pth'\n            )\n        )\n        log_training_results.best_val_acc = val_acc\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:29.457923Z","iopub.execute_input":"2023-05-07T09:41:29.459106Z","iopub.status.idle":"2023-05-07T09:41:29.466991Z","shell.execute_reply.started":"2023-05-07T09:41:29.459069Z","shell.execute_reply":"2023-05-07T09:41:29.466026Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"log_training_results.best_val_acc = 0\ntrainer.run(loader['train'], max_epochs=nb_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:41:31.193250Z","iopub.execute_input":"2023-05-07T09:41:31.193600Z","iopub.status.idle":"2023-05-07T09:50:00.528549Z","shell.execute_reply.started":"2023-05-07T09:41:31.193571Z","shell.execute_reply":"2023-05-07T09:50:00.527664Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch: 1  Train acc: 0.6000 loss: 0.6749  Val acc: 0.5526 loss: 0.6867  Test acc: 1.0000 loss: 0.6024\nNew checkpoint\nEpoch: 2  Train acc: 0.6000 loss: 0.6796  Val acc: 0.5526 loss: 0.6865  Test acc: 1.0000 loss: 0.6206\nEpoch: 3  Train acc: 0.5067 loss: 0.6932  Val acc: 0.5526 loss: 0.6932  Test acc: 0.2824 loss: 0.6952\nEpoch: 4  Train acc: 0.6000 loss: 0.6783  Val acc: 0.5526 loss: 0.6859  Test acc: 1.0000 loss: 0.6488\nEpoch: 5  Train acc: 0.6000 loss: 0.8388  Val acc: 0.5526 loss: 1.0443  Test acc: 1.0000 loss: 0.1363\nEpoch: 6  Train acc: 0.8067 loss: 0.5753  Val acc: 0.7105 loss: 0.6031  Test acc: 0.3941 loss: 0.7272\nNew checkpoint\nEpoch: 7  Train acc: 0.8267 loss: 0.4742  Val acc: 0.7105 loss: 0.6145  Test acc: 0.6112 loss: 0.7903\nEpoch: 8  Train acc: 0.8333 loss: 0.4348  Val acc: 0.6579 loss: 0.6862  Test acc: 0.6707 loss: 0.7544\nEpoch: 9  Train acc: 0.6600 loss: 0.5939  Val acc: 0.6842 loss: 0.6338  Test acc: 0.2234 loss: 0.8108\nEpoch: 10  Train acc: 0.6000 loss: 0.5067  Val acc: 0.5526 loss: 0.7963  Test acc: 1.0000 loss: 0.3043\nEpoch: 11  Train acc: 0.6000 loss: 0.4206  Val acc: 0.5526 loss: 0.7611  Test acc: 1.0000 loss: 0.3971\nEpoch: 12  Train acc: 0.8600 loss: 0.5607  Val acc: 0.6316 loss: 1.2652  Test acc: 0.7596 loss: 0.3140\nEpoch: 13  Train acc: 0.8933 loss: 0.2835  Val acc: 0.7368 loss: 0.5251  Test acc: 0.4898 loss: 1.0015\nNew checkpoint\nEpoch: 14  Train acc: 0.8733 loss: 0.3308  Val acc: 0.7632 loss: 0.7473  Test acc: 0.6383 loss: 0.6852\nNew checkpoint\nEpoch: 15  Train acc: 0.9067 loss: 0.2872  Val acc: 0.7632 loss: 0.4495  Test acc: 0.5047 loss: 0.9255\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"State:\n\titeration: 45\n\tepoch: 15\n\tepoch_length: 3\n\tmax_epochs: 15\n\toutput: <class 'tuple'>\n\tbatch: <class 'list'>\n\tmetrics: <class 'dict'>\n\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n\tseed: <class 'NoneType'>\n\ttimes: <class 'dict'>"},"metadata":{}}]},{"cell_type":"code","source":"free_gpu_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:50:11.608952Z","iopub.execute_input":"2023-05-07T09:50:11.609314Z","iopub.status.idle":"2023-05-07T09:50:12.183699Z","shell.execute_reply.started":"2023-05-07T09:50:11.609285Z","shell.execute_reply":"2023-05-07T09:50:12.182597Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfree_gpu_cache\u001b[49m()\n","\u001b[0;31mNameError\u001b[0m: name 'free_gpu_cache' is not defined"],"ename":"NameError","evalue":"name 'free_gpu_cache' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# TRAIN BERT GCN","metadata":{}},{"cell_type":"code","source":"import random\nfrom model import BertGCN, BertGAT","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:01.149275Z","iopub.execute_input":"2023-05-07T09:57:01.149658Z","iopub.status.idle":"2023-05-07T09:57:01.154163Z","shell.execute_reply.started":"2023-05-07T09:57:01.149623Z","shell.execute_reply":"2023-05-07T09:57:01.153091Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument('--max_length', type=int, default=128, help='the input length for bert')\nparser.add_argument('--batch_size', type=int, default=32)\nparser.add_argument('-m', '--m', type=float, default=0.7, help='the factor balancing BERT and GCN prediction')\nparser.add_argument('--nb_epochs', type=int, default=15)\nparser.add_argument('--bert_init', type=str, default='roberta-base',\n                    choices=['roberta-base', 'roberta-large', 'bert-base-uncased', 'bert-large-uncased'])\nparser.add_argument('--pretrained_bert_ckpt', default='checkpoint/roberta-base_covid-semi')\nparser.add_argument('--dataset', default='covid-semi', choices=['20ng', 'R8', 'R52', 'ohsumed', 'mr', 'covid-semi'])\nparser.add_argument('--checkpoint_dir', default=None, help='checkpoint directory, [bert_init]_[gcn_model]_[dataset] if not specified')\nparser.add_argument('--gcn_model', type=str, default='gcn', choices=['gcn', 'gat'])\nparser.add_argument('--gcn_layers', type=int, default=2)\nparser.add_argument('--n_hidden', type=int, default=200, help='the dimension of gcn hidden layer, the dimension for gat is n_hidden * heads')\nparser.add_argument('--heads', type=int, default=8, help='the number of attentionn heads for gat')\nparser.add_argument('--dropout', type=float, default=0.5)\nparser.add_argument('--gcn_lr', type=float, default=1e-3)\nparser.add_argument('--bert_lr', type=float, default=1e-5)\n\nargs = parser.parse_args()\nmax_length = args.max_length\nbatch_size = args.batch_size\nm = args.m\nnb_epochs = args.nb_epochs\nbert_init = args.bert_init\npretrained_bert_ckpt = args.pretrained_bert_ckpt\ndataset = args.dataset\ncheckpoint_dir = args.checkpoint_dir\ngcn_model = args.gcn_model\ngcn_layers = args.gcn_layers\nn_hidden = args.n_hidden\nheads = args.heads\ndropout = args.dropout\ngcn_lr = args.gcn_lr\nbert_lr = args.bert_lr\n\nif checkpoint_dir is None:\n    ckpt_dir = './checkpoint/{}_{}_{}'.format(bert_init, gcn_model, dataset)\nelse:\n    ckpt_dir = checkpoint_dir\nos.makedirs(ckpt_dir, exist_ok=True)\n# shutil.copy(os.path.basename(__file__), ckpt_dir)\n\nsh = logging.StreamHandler(sys.stdout)\nsh.setFormatter(logging.Formatter('%(message)s'))\nsh.setLevel(logging.INFO)\nfh = logging.FileHandler(filename=os.path.join(ckpt_dir, 'training.log'), mode='w')\nfh.setFormatter(logging.Formatter('%(message)s'))\nfh.setLevel(logging.INFO)\nlogger = logging.getLogger('training logger')\nlogger.addHandler(sh)\nlogger.addHandler(fh)\nlogger.setLevel(logging.INFO)\n\ncpu = th.device('cpu')\ngpu = th.device('cuda:0')\n\nlogger.info('arguments:')\nlogger.info(str(args))\nlogger.info('checkpoints will be saved in {}'.format(ckpt_dir))","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:01.805154Z","iopub.execute_input":"2023-05-07T09:57:01.805510Z","iopub.status.idle":"2023-05-07T09:57:01.835476Z","shell.execute_reply.started":"2023-05-07T09:57:01.805481Z","shell.execute_reply":"2023-05-07T09:57:01.834707Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"arguments:\narguments:\narguments:\narguments:\nNamespace(max_length=128, batch_size=32, m=0.7, nb_epochs=15, bert_init='roberta-base', pretrained_bert_ckpt='checkpoint/roberta-base_covid-semi', dataset='covid-semi', checkpoint_dir=None, gcn_model='gcn', gcn_layers=2, n_hidden=200, heads=8, dropout=0.5, gcn_lr=0.001, bert_lr=1e-05)\nNamespace(max_length=128, batch_size=32, m=0.7, nb_epochs=15, bert_init='roberta-base', pretrained_bert_ckpt='checkpoint/roberta-base_covid-semi', dataset='covid-semi', checkpoint_dir=None, gcn_model='gcn', gcn_layers=2, n_hidden=200, heads=8, dropout=0.5, gcn_lr=0.001, bert_lr=1e-05)\nNamespace(max_length=128, batch_size=32, m=0.7, nb_epochs=15, bert_init='roberta-base', pretrained_bert_ckpt='checkpoint/roberta-base_covid-semi', dataset='covid-semi', checkpoint_dir=None, gcn_model='gcn', gcn_layers=2, n_hidden=200, heads=8, dropout=0.5, gcn_lr=0.001, bert_lr=1e-05)\nNamespace(max_length=128, batch_size=32, m=0.7, nb_epochs=15, bert_init='roberta-base', pretrained_bert_ckpt='checkpoint/roberta-base_covid-semi', dataset='covid-semi', checkpoint_dir=None, gcn_model='gcn', gcn_layers=2, n_hidden=200, heads=8, dropout=0.5, gcn_lr=0.001, bert_lr=1e-05)\ncheckpoints will be saved in ./checkpoint/roberta-base_gcn_covid-semi\ncheckpoints will be saved in ./checkpoint/roberta-base_gcn_covid-semi\ncheckpoints will be saved in ./checkpoint/roberta-base_gcn_covid-semi\ncheckpoints will be saved in ./checkpoint/roberta-base_gcn_covid-semi\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls checkpoint/roberta-base_covid-semi","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:03.548445Z","iopub.execute_input":"2023-05-07T09:57:03.548837Z","iopub.status.idle":"2023-05-07T09:57:04.679233Z","shell.execute_reply.started":"2023-05-07T09:57:03.548805Z","shell.execute_reply":"2023-05-07T09:57:04.677951Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\ncheckpoint.pth\ttraining.log\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data Preprocess\nadj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(dataset)\n'''\nadj: n*n sparse adjacency matrix\ny_train, y_val, y_test: n*c matrices \ntrain_mask, val_mask, test_mask: n-d bool array\n'''","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:04.681791Z","iopub.execute_input":"2023-05-07T09:57:04.682260Z","iopub.status.idle":"2023-05-07T09:57:05.927654Z","shell.execute_reply.started":"2023-05-07T09:57:04.682213Z","shell.execute_reply":"2023-05-07T09:57:05.926622Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"(150, 300) (150, 2) (8645, 300) (8645, 2) (13599, 300) (13599, 2)\n22244\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"'\\nadj: n*n sparse adjacency matrix\\ny_train, y_val, y_test: n*c matrices \\ntrain_mask, val_mask, test_mask: n-d bool array\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# compute number of real train/val/test/word nodes and number of classes\nnb_node = features.shape[0]\nnb_train, nb_val, nb_test = train_mask.sum(), val_mask.sum(), test_mask.sum()\nnb_word = nb_node - nb_train - nb_val - nb_test\nnb_class = y_train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:05.929660Z","iopub.execute_input":"2023-05-07T09:57:05.930041Z","iopub.status.idle":"2023-05-07T09:57:05.935399Z","shell.execute_reply.started":"2023-05-07T09:57:05.930008Z","shell.execute_reply":"2023-05-07T09:57:05.934483Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# instantiate model according to class number\nif gcn_model == 'gcn':\n    model = BertGCN(nb_class=nb_class, pretrained_model=bert_init, m=m, gcn_layers=gcn_layers,\n                    n_hidden=n_hidden, dropout=dropout)\nelse:\n    model = BertGAT(nb_class=nb_class, pretrained_model=bert_init, m=m, gcn_layers=gcn_layers,\n                    heads=heads, n_hidden=n_hidden, dropout=dropout)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:05.937050Z","iopub.execute_input":"2023-05-07T09:57:05.937807Z","iopub.status.idle":"2023-05-07T09:57:08.395700Z","shell.execute_reply.started":"2023-05-07T09:57:05.937769Z","shell.execute_reply":"2023-05-07T09:57:08.394731Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"if pretrained_bert_ckpt is not None:\n    ckpt = th.load(os.path.join(pretrained_bert_ckpt, \"checkpoint.pth\"), map_location=gpu)\n    model.bert_model.load_state_dict(ckpt['bert_model'])\n    model.classifier.load_state_dict(ckpt['classifier'])","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:08.398763Z","iopub.execute_input":"2023-05-07T09:57:08.399124Z","iopub.status.idle":"2023-05-07T09:57:09.559788Z","shell.execute_reply.started":"2023-05-07T09:57:08.399090Z","shell.execute_reply":"2023-05-07T09:57:09.558850Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# load documents and compute input encodings\ncorpse_file = './data/corpus/' + dataset +'_shuffle.txt'\nwith open(corpse_file, 'r') as f:\n    text = f.read()\n    text = text.replace('\\\\', '')\n    text = text.split('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:09.561224Z","iopub.execute_input":"2023-05-07T09:57:09.561562Z","iopub.status.idle":"2023-05-07T09:57:09.589150Z","shell.execute_reply.started":"2023-05-07T09:57:09.561531Z","shell.execute_reply":"2023-05-07T09:57:09.588193Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def encode_input(text, tokenizer):\n    input = tokenizer(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n#     print(input.keys())\n    return input.input_ids, input.attention_mask\n\n\ninput_ids, attention_mask = encode_input(text, model.tokenizer)\ninput_ids = th.cat([input_ids[:-nb_test], th.zeros((nb_word, max_length), dtype=th.long), input_ids[-nb_test:]])\nattention_mask = th.cat([attention_mask[:-nb_test], th.zeros((nb_word, max_length), dtype=th.long), attention_mask[-nb_test:]])\n\n# transform one-hot label to class ID for pytorch computation\ny = y_train + y_test + y_val\ny_train = y_train.argmax(axis=1)\ny = y.argmax(axis=1)\n\n# document mask used for update feature\ndoc_mask  = train_mask + val_mask + test_mask","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:09.590546Z","iopub.execute_input":"2023-05-07T09:57:09.591120Z","iopub.status.idle":"2023-05-07T09:57:13.065790Z","shell.execute_reply.started":"2023-05-07T09:57:09.591083Z","shell.execute_reply":"2023-05-07T09:57:13.064783Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# build DGL Graph\nadj_norm = normalize_adj(adj + sp.eye(adj.shape[0]))\ng = dgl.from_scipy(adj_norm.astype('float32'), eweight_name='edge_weight')\ng.ndata['input_ids'], g.ndata['attention_mask'] = input_ids, attention_mask\ng.ndata['label'], g.ndata['train'], g.ndata['val'], g.ndata['test'] = \\\n    th.LongTensor(y), th.FloatTensor(train_mask), th.FloatTensor(val_mask), th.FloatTensor(test_mask)\ng.ndata['label_train'] = th.LongTensor(y_train)\ng.ndata['cls_feats'] = th.zeros((nb_node, model.feat_dim))\n\nlogger.info('graph information:')\nlogger.info(str(g))","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:13.067372Z","iopub.execute_input":"2023-05-07T09:57:13.068071Z","iopub.status.idle":"2023-05-07T09:57:15.274047Z","shell.execute_reply.started":"2023-05-07T09:57:13.068038Z","shell.execute_reply":"2023-05-07T09:57:15.273116Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"graph information:\ngraph information:\ngraph information:\ngraph information:\nGraph(num_nodes=22244, num_edges=7887278,\n      ndata_schemes={'input_ids': Scheme(shape=(128,), dtype=torch.int64), 'attention_mask': Scheme(shape=(128,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'train': Scheme(shape=(), dtype=torch.float32), 'val': Scheme(shape=(), dtype=torch.float32), 'test': Scheme(shape=(), dtype=torch.float32), 'label_train': Scheme(shape=(), dtype=torch.int64), 'cls_feats': Scheme(shape=(768,), dtype=torch.float32)}\n      edata_schemes={'edge_weight': Scheme(shape=(), dtype=torch.float32)})\nGraph(num_nodes=22244, num_edges=7887278,\n      ndata_schemes={'input_ids': Scheme(shape=(128,), dtype=torch.int64), 'attention_mask': Scheme(shape=(128,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'train': Scheme(shape=(), dtype=torch.float32), 'val': Scheme(shape=(), dtype=torch.float32), 'test': Scheme(shape=(), dtype=torch.float32), 'label_train': Scheme(shape=(), dtype=torch.int64), 'cls_feats': Scheme(shape=(768,), dtype=torch.float32)}\n      edata_schemes={'edge_weight': Scheme(shape=(), dtype=torch.float32)})\nGraph(num_nodes=22244, num_edges=7887278,\n      ndata_schemes={'input_ids': Scheme(shape=(128,), dtype=torch.int64), 'attention_mask': Scheme(shape=(128,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'train': Scheme(shape=(), dtype=torch.float32), 'val': Scheme(shape=(), dtype=torch.float32), 'test': Scheme(shape=(), dtype=torch.float32), 'label_train': Scheme(shape=(), dtype=torch.int64), 'cls_feats': Scheme(shape=(768,), dtype=torch.float32)}\n      edata_schemes={'edge_weight': Scheme(shape=(), dtype=torch.float32)})\nGraph(num_nodes=22244, num_edges=7887278,\n      ndata_schemes={'input_ids': Scheme(shape=(128,), dtype=torch.int64), 'attention_mask': Scheme(shape=(128,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'train': Scheme(shape=(), dtype=torch.float32), 'val': Scheme(shape=(), dtype=torch.float32), 'test': Scheme(shape=(), dtype=torch.float32), 'label_train': Scheme(shape=(), dtype=torch.int64), 'cls_feats': Scheme(shape=(768,), dtype=torch.float32)}\n      edata_schemes={'edge_weight': Scheme(shape=(), dtype=torch.float32)})\n","output_type":"stream"}]},{"cell_type":"code","source":"# create index loader\ntrain_idx = Data.TensorDataset(th.arange(0, nb_train, dtype=th.long))\nval_idx = Data.TensorDataset(th.arange(nb_train, nb_train + nb_val, dtype=th.long))\ntest_idx = Data.TensorDataset(th.arange(nb_node-nb_test, nb_node, dtype=th.long))\ndoc_idx = Data.ConcatDataset([train_idx, val_idx, test_idx])\n\nidx_loader_train = Data.DataLoader(train_idx, batch_size=batch_size, shuffle=True)\nidx_loader_val = Data.DataLoader(val_idx, batch_size=batch_size)\nidx_loader_test = Data.DataLoader(test_idx, batch_size=batch_size)\nidx_loader = Data.DataLoader(doc_idx, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:15.276858Z","iopub.execute_input":"2023-05-07T09:57:15.277545Z","iopub.status.idle":"2023-05-07T09:57:15.285327Z","shell.execute_reply.started":"2023-05-07T09:57:15.277507Z","shell.execute_reply":"2023-05-07T09:57:15.284353Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# Training\ndef update_feature():\n    global model, g, doc_mask\n    # no gradient needed, uses a large batchsize to speed up the process\n    dataloader = Data.DataLoader(\n        Data.TensorDataset(g.ndata['input_ids'][doc_mask], g.ndata['attention_mask'][doc_mask]),\n        batch_size=1024\n    )\n    with th.no_grad():\n        model = model.to(gpu)\n        model.eval()\n        cls_list = []\n        for i, batch in enumerate(dataloader):\n            input_ids, attention_mask = [x.to(gpu) for x in batch]\n            output = model.bert_model(input_ids=input_ids, attention_mask=attention_mask)[0][:, 0]\n            cls_list.append(output.cpu())\n        cls_feat = th.cat(cls_list, axis=0)\n    g = g.to(cpu)\n    g.ndata['cls_feats'][doc_mask] = cls_feat\n    return g","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:15.286787Z","iopub.execute_input":"2023-05-07T09:57:15.287146Z","iopub.status.idle":"2023-05-07T09:57:15.301105Z","shell.execute_reply.started":"2023-05-07T09:57:15.287114Z","shell.execute_reply":"2023-05-07T09:57:15.300220Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"optimizer = th.optim.Adam([\n        {'params': model.bert_model.parameters(), 'lr': bert_lr},\n        {'params': model.classifier.parameters(), 'lr': bert_lr},\n        {'params': model.gcn.parameters(), 'lr': gcn_lr},\n    ], lr=1e-3\n)\nscheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30], gamma=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:15.302321Z","iopub.execute_input":"2023-05-07T09:57:15.303188Z","iopub.status.idle":"2023-05-07T09:57:15.313464Z","shell.execute_reply.started":"2023-05-07T09:57:15.303156Z","shell.execute_reply":"2023-05-07T09:57:15.312586Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"def train_step(engine, batch):\n    global model, g, optimizer\n    model.train()\n    model = model.to(gpu)\n    g = g.to(gpu)\n    optimizer.zero_grad()\n    (idx, ) = [x.to(gpu) for x in batch]\n    optimizer.zero_grad()\n    train_mask = g.ndata['train'][idx].type(th.BoolTensor)\n    y_pred = model(g, idx)[train_mask]\n    y_true = g.ndata['label_train'][idx][train_mask]\n    loss = F.nll_loss(y_pred, y_true)\n    loss.backward()\n    optimizer.step()\n    g.ndata['cls_feats'].detach_()\n    train_loss = loss.item()\n    with th.no_grad():\n        if train_mask.sum() > 0:\n            y_true = y_true.detach().cpu()\n            y_pred = y_pred.argmax(axis=1).detach().cpu()\n            train_acc = accuracy_score(y_true, y_pred)\n        else:\n            train_acc = 1\n    return train_loss, train_acc\n\n\ntrainer = Engine(train_step)\n\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef reset_graph(trainer):\n    scheduler.step()\n    update_feature()\n    th.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:15.314921Z","iopub.execute_input":"2023-05-07T09:57:15.315470Z","iopub.status.idle":"2023-05-07T09:57:15.325387Z","shell.execute_reply.started":"2023-05-07T09:57:15.315439Z","shell.execute_reply":"2023-05-07T09:57:15.324726Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"def test_step(engine, batch):\n    global model, g\n    with th.no_grad():\n        model.eval()\n        model = model.to(gpu)\n        g = g.to(gpu)\n        (idx, ) = [x.to(gpu) for x in batch]\n        y_pred = model(g, idx)\n        y_true = g.ndata['label'][idx]\n        return y_pred, y_true\n\n\nevaluator = Engine(test_step)\nmetrics={\n    'acc': Accuracy(),\n    'nll': Loss(th.nn.NLLLoss())\n}\nfor n, f in metrics.items():\n    f.attach(evaluator, n)\n\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_training_results(trainer):\n    evaluator.run(idx_loader_train)\n    metrics = evaluator.state.metrics\n    train_acc, train_nll = metrics[\"acc\"], metrics[\"nll\"]\n    evaluator.run(idx_loader_val)\n    metrics = evaluator.state.metrics\n    val_acc, val_nll = metrics[\"acc\"], metrics[\"nll\"]\n    evaluator.run(idx_loader_test)\n    metrics = evaluator.state.metrics\n    test_acc, test_nll = metrics[\"acc\"], metrics[\"nll\"]\n    logger.info(\n        \"Epoch: {}  Train acc: {:.4f} loss: {:.4f}  Val acc: {:.4f} loss: {:.4f}  Test acc: {:.4f} loss: {:.4f}\"\n        .format(trainer.state.epoch, train_acc, train_nll, val_acc, val_nll, test_acc, test_nll)\n    )\n    if val_acc > log_training_results.best_val_acc:\n        logger.info(\"New checkpoint\")\n        th.save(\n            {\n                'bert_model': model.bert_model.state_dict(),\n                'classifier': model.classifier.state_dict(),\n                'gcn': model.gcn.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'epoch': trainer.state.epoch,\n            },\n            os.path.join(\n                ckpt_dir, 'checkpoint.pth'\n            )\n        )\n        log_training_results.best_val_acc = val_acc\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:15.326569Z","iopub.execute_input":"2023-05-07T09:57:15.327499Z","iopub.status.idle":"2023-05-07T09:57:15.342323Z","shell.execute_reply.started":"2023-05-07T09:57:15.327466Z","shell.execute_reply":"2023-05-07T09:57:15.341389Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"log_training_results.best_val_acc = 0\ng = update_feature()\ntrainer.run(idx_loader, max_epochs=nb_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:57:17.801114Z","iopub.execute_input":"2023-05-07T09:57:17.801969Z","iopub.status.idle":"2023-05-07T09:57:46.544601Z","shell.execute_reply.started":"2023-05-07T09:57:17.801929Z","shell.execute_reply":"2023-05-07T09:57:46.543230Z"},"trusted":true},"execution_count":90,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m log_training_results\u001b[38;5;241m.\u001b[39mbest_val_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m g \u001b[38;5;241m=\u001b[39m update_feature()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epochs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:892\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:935\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:993\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:959\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 959\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    961\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:1087\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1087\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:1068\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n","Cell \u001b[0;32mIn[88], line 5\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(gpu)\n\u001b[0;32m----> 5\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m (idx, ) \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mto(gpu) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dgl/heterograph.py:5709\u001b[0m, in \u001b[0;36mDGLGraph.to\u001b[0;34m(self, device, **kwargs)\u001b[0m\n\u001b[1;32m   5706\u001b[0m ret \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5708\u001b[0m \u001b[38;5;66;03m# 1. Copy graph structure\u001b[39;00m\n\u001b[0;32m-> 5709\u001b[0m ret\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dgl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5711\u001b[0m \u001b[38;5;66;03m# 2. Copy features\u001b[39;00m\n\u001b[1;32m   5712\u001b[0m \u001b[38;5;66;03m# TODO(minjie): handle initializer\u001b[39;00m\n\u001b[1;32m   5713\u001b[0m new_nframes \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/dgl/heterograph_index.py:255\u001b[0m, in \u001b[0;36mHeteroGraphIndex.copy_to\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy_to\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Copy this immutable graph index to the given device context.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m    NOTE: this method only works for immutable graph index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m        The graph index on the given device context.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CAPI_DGLHeteroCopyTo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_id\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:295\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:227\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:217\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FuncCall3\u001b[0;34m()\u001b[0m\n","\u001b[0;31mDGLError\u001b[0m: [09:57:46] /opt/dgl/src/runtime/c_runtime_api.cc:82: Check failed: allow_missing: Device API cuda is not enabled. Please install the cuda version of dgl.\nStack trace:\n  [bt] (0) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x75) [0x7c6e79547e55]\n  [bt] (1) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::DeviceAPIManager::GetAPI(std::string, bool)+0x1f2) [0x7c6e798c75f2]\n  [bt] (2) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::DeviceAPI::Get(DGLContext, bool)+0x1e1) [0x7c6e798c1ba1]\n  [bt] (3) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext)+0x13b) [0x7c6e798e4acb]\n  [bt] (4) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DGLContext const&) const+0xc3) [0x7c6e7991ee23]\n  [bt] (5) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0x3ef) [0x7c6e79a2c79f]\n  [bt] (6) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0xf6) [0x7c6e79930286]\n  [bt] (7) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(+0x52cbb6) [0x7c6e7993fbb6]\n  [bt] (8) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7c6e798c6bb8]\n\n"],"ename":"DGLError","evalue":"[09:57:46] /opt/dgl/src/runtime/c_runtime_api.cc:82: Check failed: allow_missing: Device API cuda is not enabled. Please install the cuda version of dgl.\nStack trace:\n  [bt] (0) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x75) [0x7c6e79547e55]\n  [bt] (1) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::DeviceAPIManager::GetAPI(std::string, bool)+0x1f2) [0x7c6e798c75f2]\n  [bt] (2) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::DeviceAPI::Get(DGLContext, bool)+0x1e1) [0x7c6e798c1ba1]\n  [bt] (3) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext)+0x13b) [0x7c6e798e4acb]\n  [bt] (4) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DGLContext const&) const+0xc3) [0x7c6e7991ee23]\n  [bt] (5) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0x3ef) [0x7c6e79a2c79f]\n  [bt] (6) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0xf6) [0x7c6e79930286]\n  [bt] (7) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(+0x52cbb6) [0x7c6e7993fbb6]\n  [bt] (8) /opt/conda/lib/python3.10/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7c6e798c6bb8]\n\n","output_type":"error"}]},{"cell_type":"code","source":"log_training_results.best_val_acc","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:56:35.520070Z","iopub.execute_input":"2023-05-07T09:56:35.520445Z","iopub.status.idle":"2023-05-07T09:56:35.530688Z","shell.execute_reply.started":"2023-05-07T09:56:35.520415Z","shell.execute_reply":"2023-05-07T09:56:35.529751Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:31:58.140983Z","iopub.execute_input":"2023-05-07T09:31:58.141345Z","iopub.status.idle":"2023-05-07T09:31:58.145589Z","shell.execute_reply.started":"2023-05-07T09:31:58.141317Z","shell.execute_reply":"2023-05-07T09:31:58.144630Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"# DOWNLOAD KAGGLE WORKING DIRECTORY","metadata":{}},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/BertGCN","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:59:05.565848Z","iopub.execute_input":"2023-05-07T09:59:05.566249Z","iopub.status.idle":"2023-05-07T10:00:54.456651Z","shell.execute_reply.started":"2023-05-07T09:59:05.566221Z","shell.execute_reply":"2023-05-07T10:00:54.455464Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n  adding: kaggle/working/BertGCN/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/objects/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/objects/pack/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/objects/pack/pack-556ec751a2923961f4f098d7405c1f2506b40387.idx (deflated 20%)\n  adding: kaggle/working/BertGCN/.git/objects/pack/pack-556ec751a2923961f4f098d7405c1f2506b40387.pack (deflated 0%)\n  adding: kaggle/working/BertGCN/.git/objects/info/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/FETCH_HEAD (deflated 5%)\n  adding: kaggle/working/BertGCN/.git/logs/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/logs/HEAD (deflated 27%)\n  adding: kaggle/working/BertGCN/.git/logs/refs/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/logs/refs/heads/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/logs/refs/heads/main (deflated 27%)\n  adding: kaggle/working/BertGCN/.git/logs/refs/remotes/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/logs/refs/remotes/origin/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/logs/refs/remotes/origin/HEAD (deflated 27%)\n  adding: kaggle/working/BertGCN/.git/branches/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/HEAD (stored 0%)\n  adding: kaggle/working/BertGCN/.git/index (deflated 49%)\n  adding: kaggle/working/BertGCN/.git/refs/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/refs/heads/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/refs/heads/main (stored 0%)\n  adding: kaggle/working/BertGCN/.git/refs/tags/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/refs/remotes/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/refs/remotes/origin/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/refs/remotes/origin/HEAD (stored 0%)\n  adding: kaggle/working/BertGCN/.git/hooks/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/hooks/pre-rebase.sample (deflated 59%)\n  adding: kaggle/working/BertGCN/.git/hooks/pre-receive.sample (deflated 40%)\n  adding: kaggle/working/BertGCN/.git/hooks/post-update.sample (deflated 27%)\n  adding: kaggle/working/BertGCN/.git/hooks/pre-commit.sample (deflated 45%)\n  adding: kaggle/working/BertGCN/.git/hooks/fsmonitor-watchman.sample (deflated 52%)\n  adding: kaggle/working/BertGCN/.git/hooks/update.sample (deflated 68%)\n  adding: kaggle/working/BertGCN/.git/hooks/applypatch-msg.sample (deflated 42%)\n  adding: kaggle/working/BertGCN/.git/hooks/pre-applypatch.sample (deflated 38%)\n  adding: kaggle/working/BertGCN/.git/hooks/commit-msg.sample (deflated 44%)\n  adding: kaggle/working/BertGCN/.git/hooks/pre-push.sample (deflated 50%)\n  adding: kaggle/working/BertGCN/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n  adding: kaggle/working/BertGCN/.git/hooks/pre-merge-commit.sample (deflated 39%)\n  adding: kaggle/working/BertGCN/.git/description (deflated 14%)\n  adding: kaggle/working/BertGCN/.git/config (deflated 32%)\n  adding: kaggle/working/BertGCN/.git/packed-refs (deflated 9%)\n  adding: kaggle/working/BertGCN/.git/info/ (stored 0%)\n  adding: kaggle/working/BertGCN/.git/info/exclude (deflated 28%)\n  adding: kaggle/working/BertGCN/.git/ORIG_HEAD (stored 0%)\n  adding: kaggle/working/BertGCN/finetune_bert.py (deflated 65%)\n  adding: kaggle/working/BertGCN/remove_words.py (deflated 65%)\n  adding: kaggle/working/BertGCN/utils/ (stored 0%)\n  adding: kaggle/working/BertGCN/utils/utils.py (deflated 73%)\n  adding: kaggle/working/BertGCN/utils/__init__.py (stored 0%)\n  adding: kaggle/working/BertGCN/utils/__pycache__/ (stored 0%)\n  adding: kaggle/working/BertGCN/utils/__pycache__/__init__.cpython-310.pyc (deflated 21%)\n  adding: kaggle/working/BertGCN/utils/__pycache__/utils.cpython-310.pyc (deflated 56%)\n  adding: kaggle/working/BertGCN/build_graph.py (deflated 78%)\n  adding: kaggle/working/BertGCN/requirements.txt (deflated 31%)\n  adding: kaggle/working/BertGCN/.gitignore (deflated 47%)\n  adding: kaggle/working/BertGCN/train_bert_gcn.py (deflated 68%)\n  adding: kaggle/working/BertGCN/data/ (stored 0%)\n  adding: kaggle/working/BertGCN/data/covid-semi.test.index (deflated 53%)\n  adding: kaggle/working/BertGCN/data/ind.covid-semi.allx (deflated 37%)\n  adding: kaggle/working/BertGCN/data/ind.covid-semi.adj (deflated 27%)\n  adding: kaggle/working/BertGCN/data/ind.covid-semi.x (deflated 99%)\n  adding: kaggle/working/BertGCN/data/ohsumed.txt (deflated 93%)\n  adding: kaggle/working/BertGCN/data/ind.covid-semi.tx (deflated 100%)\n  adding: kaggle/working/BertGCN/data/covid-semi_shuffle.txt (deflated 80%)\n  adding: kaggle/working/BertGCN/data/ind.covid-semi.y (deflated 92%)\n  adding: kaggle/working/BertGCN/data/covid-semi.real_train.name (deflated 78%)\n  adding: kaggle/working/BertGCN/data/20ng.txt (deflated 96%)\n  adding: kaggle/working/BertGCN/data/ind.covid-semi.ty (deflated 100%)\n  adding: kaggle/working/BertGCN/data/covid-semi.train.index (deflated 52%)\n  adding: kaggle/working/BertGCN/data/mr.txt (deflated 81%)\n  adding: kaggle/working/BertGCN/data/ind.covid-semi.ally (deflated 100%)\n  adding: kaggle/working/BertGCN/data/R8.txt (deflated 82%)\n  adding: kaggle/working/BertGCN/data/corpus/ (stored 0%)\n  adding: kaggle/working/BertGCN/data/corpus/20ng.clean.txt (deflated 68%)\n  adding: kaggle/working/BertGCN/data/corpus/covid-semi.clean.txt (deflated 70%)\n  adding: kaggle/working/BertGCN/data/corpus/ohsumed.txt (deflated 68%)\n  adding: kaggle/working/BertGCN/data/corpus/mr.clean.txt (deflated 61%)\n  adding: kaggle/working/BertGCN/data/corpus/R52.clean.txt (deflated 71%)\n  adding: kaggle/working/BertGCN/data/corpus/R8.clean.txt (deflated 72%)\n  adding: kaggle/working/BertGCN/data/corpus/covid-semi_shuffle.txt (deflated 70%)\n  adding: kaggle/working/BertGCN/data/corpus/20ng.txt (deflated 63%)\n  adding: kaggle/working/BertGCN/data/corpus/covid-semi_labels.txt (stored 0%)\n  adding: kaggle/working/BertGCN/data/corpus/mr.txt (deflated 61%)\n  adding: kaggle/working/BertGCN/data/corpus/R8.txt (deflated 70%)\n  adding: kaggle/working/BertGCN/data/corpus/covid-semi.txt (deflated 67%)\n  adding: kaggle/working/BertGCN/data/corpus/R52.txt (deflated 69%)\n  adding: kaggle/working/BertGCN/data/corpus/ohsumed.clean.txt (deflated 70%)\n  adding: kaggle/working/BertGCN/data/corpus/covid-semi_vocab.txt (deflated 54%)\n  adding: kaggle/working/BertGCN/data/covid-semi.txt (deflated 82%)\n  adding: kaggle/working/BertGCN/data/R52.txt (deflated 80%)\n  adding: kaggle/working/BertGCN/README.md (deflated 54%)\n  adding: kaggle/working/BertGCN/checkpoint/ (stored 0%)\n  adding: kaggle/working/BertGCN/checkpoint/roberta-base_covid-semi/ (stored 0%)\n  adding: kaggle/working/BertGCN/checkpoint/roberta-base_covid-semi/training.log (deflated 82%)\n  adding: kaggle/working/BertGCN/checkpoint/roberta-base_covid-semi/checkpoint.pth (deflated 29%)\n  adding: kaggle/working/BertGCN/checkpoint/roberta-base_gcn_covid-semi/ (stored 0%)\n  adding: kaggle/working/BertGCN/checkpoint/roberta-base_gcn_covid-semi/training.log (deflated 85%)\n  adding: kaggle/working/BertGCN/prepare_data.py (deflated 62%)\n  adding: kaggle/working/BertGCN/model/ (stored 0%)\n  adding: kaggle/working/BertGCN/model/torch_gcn.py (deflated 61%)\n  adding: kaggle/working/BertGCN/model/__init__.py (stored 0%)\n  adding: kaggle/working/BertGCN/model/models.py (deflated 80%)\n  adding: kaggle/working/BertGCN/model/torch_gat.py (deflated 65%)\n  adding: kaggle/working/BertGCN/model/graphconv_edge_weight.py (deflated 72%)\n  adding: kaggle/working/BertGCN/model/__pycache__/ (stored 0%)\n  adding: kaggle/working/BertGCN/model/__pycache__/torch_gat.cpython-310.pyc (deflated 36%)\n  adding: kaggle/working/BertGCN/model/__pycache__/graphconv_edge_weight.cpython-310.pyc (deflated 41%)\n  adding: kaggle/working/BertGCN/model/__pycache__/models.cpython-310.pyc (deflated 55%)\n  adding: kaggle/working/BertGCN/model/__pycache__/torch_gcn.cpython-310.pyc (deflated 35%)\n  adding: kaggle/working/BertGCN/model/__pycache__/__init__.cpython-310.pyc (deflated 21%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!mv file.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:45:27.717115Z","iopub.execute_input":"2023-05-07T08:45:27.717516Z","iopub.status.idle":"2023-05-07T08:45:28.857282Z","shell.execute_reply.started":"2023-05-07T08:45:27.717462Z","shell.execute_reply":"2023-05-07T08:45:28.856116Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"os.chdir(\"..\")","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:46:18.294680Z","iopub.execute_input":"2023-05-07T08:46:18.295028Z","iopub.status.idle":"2023-05-07T08:46:18.302244Z","shell.execute_reply.started":"2023-05-07T08:46:18.295000Z","shell.execute_reply":"2023-05-07T08:46:18.301343Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2023-05-07T08:46:25.147863Z","iopub.execute_input":"2023-05-07T08:46:25.148220Z","iopub.status.idle":"2023-05-07T08:46:25.157620Z","shell.execute_reply.started":"2023-05-07T08:46:25.148191Z","shell.execute_reply":"2023-05-07T08:46:25.156433Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\nimport gc\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n    gc.collect()\n    torch.cuda.empty_cache()\n\n#     cuda.select_device(0)\n#     cuda.close()\n#     cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()  ","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:56:41.169107Z","iopub.execute_input":"2023-05-07T09:56:41.169512Z","iopub.status.idle":"2023-05-07T09:56:50.819423Z","shell.execute_reply.started":"2023-05-07T09:56:41.169472Z","shell.execute_reply":"2023-05-07T09:56:50.818277Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: GPUtil in /opt/conda/lib/python3.10/site-packages (1.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mInitial GPU Usage\n| ID | GPU | MEM |\n------------------\n|  0 |  0% | 61% |\nGPU Usage after emptying the cache\n| ID | GPU | MEM |\n------------------\n|  0 |  0% | 18% |\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  dgl -f https://data.dgl.ai/wheels/cu113/repo.html","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:54:03.791991Z","iopub.execute_input":"2023-05-07T09:54:03.792382Z","iopub.status.idle":"2023-05-07T09:54:20.009697Z","shell.execute_reply.started":"2023-05-07T09:54:03.792347Z","shell.execute_reply":"2023-05-07T09:54:20.008413Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nLooking in links: https://data.dgl.ai/wheels/cu113/repo.html\nCollecting dgl\n  Downloading https://data.dgl.ai/wheels/cu113/dgl-1.1.0%2Bcu113-cp310-cp310-manylinux1_x86_64.whl (86.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.5/86.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.10/site-packages (from dgl) (3.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from dgl) (4.64.1)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (1.9.3)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (1.23.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (2.28.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (5.9.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (2.1.1)\nInstalling collected packages: dgl\nSuccessfully installed dgl-1.1.0+cu113\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:55:14.777294Z","iopub.execute_input":"2023-05-07T09:55:14.777711Z","iopub.status.idle":"2023-05-07T09:55:26.051890Z","shell.execute_reply.started":"2023-05-07T09:55:14.777662Z","shell.execute_reply":"2023-05-07T09:55:26.050597Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nLooking in links: https://data.dgl.ai/wheels-test/repo.html\nCollecting dglgo\n  Using cached dglgo-0.0.2-py3-none-any.whl (63 kB)\nRequirement already satisfied: ruamel.yaml>=0.17.20 in /opt/conda/lib/python3.10/site-packages (from dglgo) (0.17.21)\nRequirement already satisfied: isort>=5.10.1 in /opt/conda/lib/python3.10/site-packages (from dglgo) (5.12.0)\nRequirement already satisfied: pydantic>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.10.7)\nRequirement already satisfied: autopep8>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (2.0.2)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from dglgo) (6.0)\nRequirement already satisfied: ogb>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.3.6)\nRequirement already satisfied: rdkit-pypi in /opt/conda/lib/python3.10/site-packages (from dglgo) (2022.9.5)\nRequirement already satisfied: numpydoc>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.5.0)\nRequirement already satisfied: typer>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (0.7.0)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.2.2)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\nRequirement already satisfied: pycodestyle>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from autopep8>=1.6.0->dglgo) (2.10.0)\nRequirement already satisfied: sphinx>=4.2 in /opt/conda/lib/python3.10/site-packages (from numpydoc>=1.1.0->dglgo) (7.0.0)\nRequirement already satisfied: Jinja2>=2.10 in /opt/conda/lib/python3.10/site-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.23.5)\nRequirement already satisfied: outdated>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (0.2.2)\nRequirement already satisfied: tqdm>=4.29.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (4.64.1)\nRequirement already satisfied: urllib3>=1.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.26.15)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (2.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.16.0)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.5.3)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.6 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (1.9.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.4.0->dglgo) (8.1.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit-pypi->dglgo) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.28.2)\nRequirement already satisfied: littleutils in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\nRequirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (59.8.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3)\nRequirement already satisfied: sphinxcontrib-applehelp in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\nRequirement already satisfied: Pygments>=2.13 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.15.0)\nRequirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\nRequirement already satisfied: sphinxcontrib-jsmath in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\nRequirement already satisfied: imagesize>=1.3 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\nRequirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (21.3)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\nRequirement already satisfied: sphinxcontrib-qthelp in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\nRequirement already satisfied: sphinxcontrib-devhelp in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\nRequirement already satisfied: docutils<0.20,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.19)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.11.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.0->sphinx>=4.2->numpydoc>=1.1.0->dglgo) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2022.12.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\nInstalling collected packages: dglgo\nSuccessfully installed dglgo-0.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall dglgo -y","metadata":{"execution":{"iopub.status.busy":"2023-05-07T09:55:08.742660Z","iopub.execute_input":"2023-05-07T09:55:08.743767Z","iopub.status.idle":"2023-05-07T09:55:10.659341Z","shell.execute_reply.started":"2023-05-07T09:55:08.743716Z","shell.execute_reply":"2023-05-07T09:55:10.658112Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nFound existing installation: dglgo 0.0.2\nUninstalling dglgo-0.0.2:\n  Successfully uninstalled dglgo-0.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# TEXT GCN TRAIN","metadata":{}},{"cell_type":"code","source":"from __future__ import division\nfrom __future__ import print_function\n\nimport time\nimport tensorflow.compat.v1 as tf\n\nfrom sklearn import metrics\nfrom utils import *\nfrom models import GCN, MLP\nimport random\nimport os\nimport sys","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:10:07.386912Z","iopub.execute_input":"2023-05-07T10:10:07.387519Z","iopub.status.idle":"2023-05-07T10:10:14.213391Z","shell.execute_reply.started":"2023-05-07T10:10:07.387487Z","shell.execute_reply":"2023-05-07T10:10:14.212497Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"seed = random.randint(1, 200)\nnp.random.seed(seed)\ntf.set_random_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:10:16.008586Z","iopub.execute_input":"2023-05-07T10:10:16.009317Z","iopub.status.idle":"2023-05-07T10:10:16.015346Z","shell.execute_reply.started":"2023-05-07T10:10:16.009285Z","shell.execute_reply":"2023-05-07T10:10:16.013066Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"flags = tf.app.flags\nFLAGS = flags.FLAGS\n# 'cora', 'citeseer', 'pubmed'\nflags.DEFINE_string('dataset', 'covid-semi', 'Dataset string.')\n# 'gcn', 'gcn_cheby', 'dense'\nflags.DEFINE_string('model', 'gcn', 'Model string.')\nflags.DEFINE_float('learning_rate', 0.02, 'Initial learning rate.')\nflags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\nflags.DEFINE_integer('hidden1', 200, 'Number of units in hidden layer 1.')\nflags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\nflags.DEFINE_float('weight_decay', 0,\n                   'Weight for L2 loss on embedding matrix.')  # 5e-4\nflags.DEFINE_integer('early_stopping', 10,\n                     'Tolerance for early stopping (# of epochs).')\nflags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:10:23.862707Z","iopub.execute_input":"2023-05-07T10:10:23.863098Z","iopub.status.idle":"2023-05-07T10:10:23.872831Z","shell.execute_reply.started":"2023-05-07T10:10:23.863058Z","shell.execute_reply":"2023-05-07T10:10:23.871875Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<absl.flags._flagvalues.FlagHolder at 0x7e06ec05c610>"},"metadata":{}}]},{"cell_type":"code","source":"sys.argv = sys.argv[2:]","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:10:39.468850Z","iopub.execute_input":"2023-05-07T10:10:39.469224Z","iopub.status.idle":"2023-05-07T10:10:39.473452Z","shell.execute_reply.started":"2023-05-07T10:10:39.469193Z","shell.execute_reply":"2023-05-07T10:10:39.472361Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Load data\ntf.disable_eager_execution()\nadj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(\n    FLAGS.dataset)\nprint(adj)\n# print(adj[0], adj[1])\nfeatures = sp.identity(features.shape[0])  # featureless\n\nprint(adj.shape)\nprint(features.shape)\n\n# Some preprocessing\nfeatures = preprocess_features(features)\nif FLAGS.model == 'gcn':\n    support = [preprocess_adj(adj)]\n    num_supports = 1\n    model_func = GCN\nelif FLAGS.model == 'gcn_cheby':\n    support = chebyshev_polynomials(adj, FLAGS.max_degree)\n    num_supports = 1 + FLAGS.max_degree\n    model_func = GCN\nelif FLAGS.model == 'dense':\n    support = [preprocess_adj(adj)]  # Not used\n    num_supports = 1\n    model_func = MLP\nelse:\n    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n\n# Define placeholders\nplaceholders = {\n    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n    'labels_mask': tf.placeholder(tf.int32),\n    'dropout': tf.placeholder_with_default(0., shape=()),\n    # helper variable for sparse dropout\n    'num_features_nonzero': tf.placeholder(tf.int32)\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:11:10.174960Z","iopub.execute_input":"2023-05-07T10:11:10.175343Z","iopub.status.idle":"2023-05-07T10:11:12.320220Z","shell.execute_reply.started":"2023-05-07T10:11:10.175314Z","shell.execute_reply":"2023-05-07T10:11:12.319321Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(170, 300) (170, 2) (8645, 300) (8645, 2) (13599, 300) (13599, 2)\n22244\n  (0, 417)\t3.4163690637646127\n  (0, 716)\t6.229976293909339\n  (0, 773)\t7.296341355643873\n  (0, 921)\t0.8799392609511113\n  (0, 942)\t4.679530739480879\n  (0, 1212)\t2.0518620568296293\n  (0, 1290)\t0.36312955192432306\n  (0, 1631)\t6.257746579409705\n  (0, 2042)\t4.755516646458801\n  (0, 2218)\t3.3368570008368788\n  (0, 2240)\t0.39511649507522584\n  (0, 2937)\t2.9041650800285006\n  (0, 3568)\t3.3925178479424325\n  (0, 3895)\t10.121796592019965\n  (0, 4157)\t3.102313706057942\n  (0, 4581)\t3.423289506609186\n  (0, 5365)\t2.7781515452356014\n  (0, 5805)\t0.399381439250732\n  (0, 6276)\t1.941053851747961\n  (0, 6959)\t1.1513784207999556\n  (0, 7328)\t2.957199776684587\n  (0, 7374)\t6.090517713191141\n  (0, 7416)\t3.0997979814606946\n  (0, 7683)\t2.5252193208485596\n  (0, 8301)\t4.367751115450038\n  :\t:\n  (22243, 10997)\t3.6266644726009734\n  (22243, 11094)\t10.897327654037493\n  (22243, 11145)\t4.036393979495595\n  (22243, 11183)\t1.161454072788697\n  (22243, 11198)\t4.461277173460861\n  (22243, 11266)\t4.2987582439630865\n  (22243, 11562)\t1.050245762660714\n  (22243, 12055)\t6.253036642688916\n  (22243, 12057)\t3.2029275982568532\n  (22243, 12158)\t17.31116240278897\n  (22243, 12194)\t3.5687970902804245\n  (22243, 12387)\t26.863389600204123\n  (22243, 12407)\t10.620032612394628\n  (22243, 12538)\t2.20278740033204\n  (22243, 12680)\t6.141811007578692\n  (22243, 12852)\t14.689785734156121\n  (22243, 12907)\t5.87984145815247\n  (22243, 12976)\t3.6835726048728525\n  (22243, 13029)\t3.6525279831908923\n  (22243, 13094)\t5.884128705238973\n  (22243, 13219)\t4.795790545596741\n  (22243, 13494)\t5.060898296009983\n  (22243, 13524)\t4.17359510100908\n  (22243, 13560)\t3.7487119070438144\n  (22243, 13591)\t3.5103008835988163\n(22244, 22244)\n(22244, 22244)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nprint(features[2][1])\nmodel = model_func(placeholders, input_dim=features[2][1], logging=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:11:15.069973Z","iopub.execute_input":"2023-05-07T10:11:15.070339Z","iopub.status.idle":"2023-05-07T10:11:15.293518Z","shell.execute_reply.started":"2023-05-07T10:11:15.070311Z","shell.execute_reply":"2023-05-07T10:11:15.292705Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"22244\nTensor(\"graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0\", shape=(None, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"session_conf = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\nsess = tf.Session(config=session_conf)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:11:17.583703Z","iopub.execute_input":"2023-05-07T10:11:17.584082Z","iopub.status.idle":"2023-05-07T10:11:19.438976Z","shell.execute_reply.started":"2023-05-07T10:11:17.584049Z","shell.execute_reply":"2023-05-07T10:11:19.438058Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def evaluate(features, support, labels, mask, placeholders):\n    t_test = time.time()\n    feed_dict_val = construct_feed_dict(\n        features, support, labels, mask, placeholders)\n    outs_val = sess.run([model.loss, model.accuracy, model.pred, model.labels], feed_dict=feed_dict_val)\n    return outs_val[0], outs_val[1], outs_val[2], outs_val[3], (time.time() - t_test)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<function utils.construct_feed_dict(features, support, labels, labels_mask, placeholders)>"},"metadata":{}}]},{"cell_type":"code","source":"# Init variables\nsess.run(tf.global_variables_initializer())\n\ncost_val = []\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:11:29.253115Z","iopub.execute_input":"2023-05-07T10:11:29.253462Z","iopub.status.idle":"2023-05-07T10:11:29.319585Z","shell.execute_reply.started":"2023-05-07T10:11:29.253433Z","shell.execute_reply":"2023-05-07T10:11:29.318625Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Train model\nfor epoch in range(FLAGS.epochs):\n\n    t = time.time()\n    # Construct feed dictionary\n    feed_dict = construct_feed_dict(\n        features, support, y_train, train_mask, placeholders)\n    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n\n    # Training step\n    outs = sess.run([model.opt_op, model.loss, model.accuracy,\n                     model.layers[0].embedding], feed_dict=feed_dict)\n\n    # Validation\n    cost, acc, pred, labels, duration = evaluate(\n        features, support, y_val, val_mask, placeholders)\n    cost_val.append(cost)\n\n    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n          \"train_acc=\", \"{:.5f}\".format(\n              outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n\n    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n        print(\"Early stopping...\")\n        break\n\nprint(\"Optimization Finished!\")","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:11:30.746826Z","iopub.execute_input":"2023-05-07T10:11:30.747204Z","iopub.status.idle":"2023-05-07T10:11:41.689918Z","shell.execute_reply.started":"2023-05-07T10:11:30.747174Z","shell.execute_reply":"2023-05-07T10:11:41.688812Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch: 0001 train_loss= 0.69314 train_acc= 0.57059 val_loss= 0.68486 val_acc= 0.66667 time= 2.84409\nEpoch: 0002 train_loss= 0.68264 train_acc= 0.60000 val_loss= 0.66669 val_acc= 0.66667 time= 0.72876\nEpoch: 0003 train_loss= 0.66214 train_acc= 0.59412 val_loss= 0.64750 val_acc= 0.66667 time= 0.72968\nEpoch: 0004 train_loss= 0.63550 train_acc= 0.60588 val_loss= 0.62982 val_acc= 0.66667 time= 0.75357\nEpoch: 0005 train_loss= 0.60218 train_acc= 0.68824 val_loss= 0.61491 val_acc= 0.83333 time= 0.73203\nEpoch: 0006 train_loss= 0.56395 train_acc= 0.80588 val_loss= 0.60371 val_acc= 0.77778 time= 0.73815\nEpoch: 0007 train_loss= 0.52196 train_acc= 0.82941 val_loss= 0.59730 val_acc= 0.72222 time= 0.73523\nEpoch: 0008 train_loss= 0.47704 train_acc= 0.88235 val_loss= 0.59713 val_acc= 0.66667 time= 0.73535\nEpoch: 0009 train_loss= 0.42930 train_acc= 0.93529 val_loss= 0.60454 val_acc= 0.66667 time= 0.73406\nEpoch: 0010 train_loss= 0.38549 train_acc= 0.93529 val_loss= 0.61984 val_acc= 0.66667 time= 0.73271\nEpoch: 0011 train_loss= 0.33852 train_acc= 0.93529 val_loss= 0.64223 val_acc= 0.66667 time= 0.73469\nEpoch: 0012 train_loss= 0.29689 train_acc= 0.92941 val_loss= 0.66917 val_acc= 0.66667 time= 0.73438\nEarly stopping...\nOptimization Finished!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Testing\ntest_cost, test_acc, pred, labels, test_duration = evaluate(\n    features, support, y_test, test_mask, placeholders)\nprint(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n\ntest_pred = []\ntest_labels = []\nprint(len(test_mask))\nfor i in range(len(test_mask)):\n    if test_mask[i]:\n        test_pred.append(pred[i])\n        test_labels.append(labels[i])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:11:41.691755Z","iopub.execute_input":"2023-05-07T10:11:41.692114Z","iopub.status.idle":"2023-05-07T10:11:42.044338Z","shell.execute_reply.started":"2023-05-07T10:11:41.692080Z","shell.execute_reply":"2023-05-07T10:11:42.043269Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Test set results: cost= 0.00000 accuracy= 0.46084 time= 0.33962\n22244\n","output_type":"stream"}]},{"cell_type":"code","source":"doc_test_list = []\nfor doc in shuffle_doc_name_list:\n    label = doc.split(\"\\t\")[1]\n    if label.find(\"test\") != -1:\n        doc_test_list.append(doc)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:18:37.985831Z","iopub.execute_input":"2023-05-07T10:18:37.986427Z","iopub.status.idle":"2023-05-07T10:18:37.998669Z","shell.execute_reply.started":"2023-05-07T10:18:37.986393Z","shell.execute_reply":"2023-05-07T10:18:37.997797Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"doc_test_pred_list = []\nfor i in range(0, len(doc_test_list)):\n    line = doc_test_list[i] + \"\\t\" + str(test_pred[i])\n    doc_test_pred_list.append(line)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:20:05.164500Z","iopub.execute_input":"2023-05-07T10:20:05.164900Z","iopub.status.idle":"2023-05-07T10:20:05.181295Z","shell.execute_reply.started":"2023-05-07T10:20:05.164867Z","shell.execute_reply":"2023-05-07T10:20:05.179968Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"doc_test_pred_list_str = '\\n'.join(doc_test_pred_list)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:20:21.941782Z","iopub.execute_input":"2023-05-07T10:20:21.942682Z","iopub.status.idle":"2023-05-07T10:20:21.948626Z","shell.execute_reply.started":"2023-05-07T10:20:21.942632Z","shell.execute_reply":"2023-05-07T10:20:21.947426Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"with open(f\"data/corpus/{dataset}_pred.txt\", 'w', encoding='utf-8') as f:\n    f.write(doc_test_pred_list_str)\n    f.close()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T10:22:57.654117Z","iopub.execute_input":"2023-05-07T10:22:57.654611Z","iopub.status.idle":"2023-05-07T10:22:57.661838Z","shell.execute_reply.started":"2023-05-07T10:22:57.654573Z","shell.execute_reply":"2023-05-07T10:22:57.660662Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}